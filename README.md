# Factify Document Intelligence System

This project is a solution for the GenAI Engineer Candidate Task from Factify.  
It transforms static business documents into structured, AI-ready JSON representations, enabling seamless integration with downstream APIs and intelligent workflows.

---

## How to Run

### 1. Install Dependencies

Make sure you have **Python 3.10+** installed.  
It's recommended to use a virtual environment.

```bash
pip install -r requirements.txt
```

### 2. Set Your OpenAI API Key

You can either:

- Add a `.env` file:

```env
OPENAI_API_KEY=your_key_here
```

- Or set an environment variable manually:

**Windows CMD**
```cmd
set OPENAI_API_KEY=your_key_here
```

**Mac/Linux**
```bash
export OPENAI_API_KEY=your_key_here
```

### 3. Place Your Input PDFs

Put your files into the following directory:

```
data/input_pdfs/
```

### 4. Run Document Processing Pipeline

```bash
python main.py
```

This will:

- Load and parse PDFs
- Classify document types using GPT-4o
- Extract structured metadata
- Save results to:

```
results/output_json/
```

### 5. Launch the API Server

```bash
uvicorn api.api_main:app --reload
```

---

## API Overview (Part 2)

### `POST /documents/analyze`

- Input: `filename` (string query param)
- Returns:
  - Document ID
  - Classification type & confidence
  - Raw text
  - Extracted metadata

---

### `GET /documents/{id}`

- Returns the full structured representation of a document (by UUID)
- Designed to be machine-consumable
- All fields follow a consistent, semantic schema

---

### `GET /documents/{id}/actions`

- Returns a list of suggested actions based on document type and content
- Filters:
  - `status`
  - `deadline`
  - `priority`

---

## Example Output

Each output is saved as a `.json` file under `results/output_json/` with the following structure:

```json
{
  "document_id": "uuid",
  "filename": "contract.PDF",
  "raw_text": "...",
  "classification": {
    "type": "Contract",
    "confidence": 0.998
  },
  "metadata": {
    "parties": [...],
    "effective_date": "...",
    "termination_date": "...",
    "key_terms": [...]
  }
}
```

---

## Project Structure

```
api/
├── api_main.py             # Entry point for API server (FastAPI)
├── endpoints.py            # API endpoint logic
└── schema.py               # Pydantic models and request/response schemas

classify/
└── classifier.py           # LLM-based document type classification

data/
└── input_pdfs/             # Folder to store input PDF files

evaluation/
└── evaluate.py             # Evaluation or scoring logic (optional or for future use)

extract/
└── metadata_extractor.py   # Prompt-based metadata extraction from documents

models/
├── openai_client.py        # Wrapper for OpenAI API calls
└── prompts.py              # Prompt templates used in extraction/classification

results/
└── output_json/            # Folder for storing final structured JSON outputs

utils/
└── config.py               # Configuration and path management

main.py                     # Main processing script
README.md                   # Project documentation
requirements.txt            # Python dependencies

```

---

## Part 1: LLM-Based Document Intelligence

- Uses **GPT-4o** with zero-shot prompts for classification
- Prompt-based extraction tailored to each document type
- Confidence scores via token-level logprobs
- Missing fields handled gracefully (`null`)
- Output schema designed for API and AI usage

---

## Part 2: AI-Ready API

- FastAPI-based mock server with 3 clean endpoints
- Each response includes field-level structure, type safety, and fallback handling
- Swagger UI available at `/docs`
- Consistent schemas with Pydantic models

---

## Part 3: Talking Points

### 1. Design Decisions

- **Zero-shot classification** chosen for flexibility and minimal training
- **Prompt templates** tuned per document type
- **Dataclass-based abstraction** keeps documents modular
- **FastAPI** selected for clarity, speed, and OpenAPI documentation

### 2. AI-Powered Feature Suggestions

#### Feature 1 - Smart Due-Date Reminders

- Leverage `due_date`, `termination_date`, and `reporting_period`
- Return actionable reminders and alerts
- Adds business value by reducing missed deadlines

#### Feature 2 - Auto-Enrichment Suggestions

- Suggest missing fields (e.g. missing totals or terms)
- Use LLMs to infer or recommend what may be added to make the doc more complete

### 3. Production Considerations

- **LLM API Failures**:
  - Wrapped in `try/except`
  - Returns HTTP 503 on failure with message
  - Logs error context for debugging

- **Caching**:
  - Processed results saved by `document_id`
  - Reuse outputs to reduce LLM calls

- **Cost**:
  - ~2 OpenAI calls per document (~500-1000 tokens total)
  - ~$0.01 per doc (based on GPT-4o pricing)

---

## Final QA Checks

- [x] Swagger UI and OpenAPI schema autogenerated
- [x] Semantic field names in all responses
- [x] Fallbacks for missing fields
- [x] Example JSON output included
- [x] Filtering works on `/actions` endpoint
- [x] Raw text exposed for downstream LLM agents

---
